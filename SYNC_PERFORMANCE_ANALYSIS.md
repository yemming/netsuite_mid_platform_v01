# 同步效能分析與優化建議

## 🔍 問題診斷

### 當前架構的問題

1. **使用 setTimeout 做背景任務（最大問題）**
   - Next.js API Route 有執行時間限制（通常 10-60 秒）
   - `setTimeout` 可能在請求結束後被終止
   - 沒有真正的背景任務處理機制
   - 這是為什麼會「卡住」和「很多資料抓不出來」的主要原因

2. **並發處理效率低**
   - `PARALLEL_REQUESTS = 5` 太低
   - 對於 204 筆 Account 記錄，需要 41 輪（204 / 5）
   - 每輪之間還有 100ms 延遲

3. **批次處理邏輯**
   - `PROCESS_BATCH = 100` 但並發只有 5，意味著每批需要 20 輪
   - 批次之間可能有瓶頸

4. **錯誤處理太保守**
   - 429 錯誤只重試 2 次
   - 但 NetSuite 的並發限制可能需要更智能的處理

## 💡 n8n 為什麼快？

1. **專用的任務排程系統**
   - 不受 HTTP 請求時間限制
   - 可以長時間運行
   - 有完善的錯誤恢復機制

2. **更好的並發控制**
   - 可以控制全局並發數
   - 有請求佇列機制

3. **智能重試**
   - 指數退避
   - 錯誤分類處理

## 🚀 優化方案

### 方案 1：改進 Next.js 架構（推薦快速實施）

**優點**：不需要額外基礎設施
**缺點**：仍有時間限制，但可以大幅改善

#### 1.1 使用 Edge Function 或 Serverless Function
- 將同步任務移到獨立的 Serverless Function
- 或使用 Supabase Edge Functions

#### 1.2 增加並發並優化批次
```typescript
PARALLEL_REQUESTS = 10-15  // 增加並發
PROCESS_BATCH = 200        // 增加批次大小
// 移除不必要的延遲
```

#### 1.3 使用更高效的批量處理
- 一次請求多筆記錄（如果 NetSuite API 支援）
- 減少資料庫寫入頻率

### 方案 2：使用 Queue 系統（最推薦，長期方案）

**優點**：真正可靠的背景任務處理
**缺點**：需要額外設定

#### 選項 A：Supabase + pg_cron
- 使用 PostgreSQL 的 `pg_cron` 擴展
- 或使用 Supabase Edge Functions 作為任務隊列

#### 選項 B：外部 Queue 服務
- **BullMQ** + Redis（推薦）
- **Inngest**（專為 Serverless 設計）
- **Trigger.dev**（開源替代方案）

### 方案 3：混合架構（最佳方案）

1. **立即優化**：提高並發、減少延遲
2. **中期方案**：引入簡單的 Queue 系統
3. **長期方案**：考慮使用 n8n 作為同步引擎，Next.js 只負責 UI

## 📊 預期改善

### 當前效能（估計）
- 5 並發 × 100ms 延遲 = 每筆記錄 ~20ms
- 204 筆 Account 記錄 = 約 4 秒（理想情況）
- 但因為 setTimeout 和時間限制，實際可能失敗

### 優化後效能（估計）
- 15 並發 × 50ms 延遲 = 每筆記錄 ~3ms
- 204 筆 Account 記錄 = 約 1 秒
- **提升 4-5 倍速度**

## 🎯 建議實施步驟

1. **立即實施**（本檔案的優化）
   - 增加並發數到 15
   - 減少延遲到 50ms
   - 優化錯誤處理
   
2. **短期方案**（1-2 週內）
   - 建立簡單的 Queue 系統（Supabase Edge Functions）
   - 或使用 Inngest（最簡單的 Queue 服務）

3. **長期方案**（1 個月內）
   - 如果資料量持續增長，考慮使用 n8n 作為同步引擎
   - Next.js 只負責 UI 和觸發同步

